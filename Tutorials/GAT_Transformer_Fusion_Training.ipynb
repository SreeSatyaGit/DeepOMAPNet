{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GATWithTransformerFusion Training\n",
        "\n",
        "This notebook demonstrates how to train the GATWithTransformerFusion model for end-to-end RNA to ADT mapping using a unified architecture that combines Graph Attention Networks (GAT) with Transformer fusion layers.\n",
        "\n",
        "## Overview\n",
        "1. Setup and imports\n",
        "2. Load and preprocess data\n",
        "3. Initialize GATWithTransformerFusion model\n",
        "4. Train the model with end-to-end optimization\n",
        "5. Evaluate performance\n",
        "6. Save trained model\n",
        "7. Make predictions on new data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scanpy as sc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add project root to Python path\n",
        "current_dir = os.getcwd()\n",
        "project_root = os.path.dirname(current_dir)\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)\n",
        "\n",
        "print(\"=== Setup Information ===\")\n",
        "print(f\"Current directory: {current_dir}\")\n",
        "print(f\"Project root: {project_root}\")\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "# Check current working directory and fix paths\n",
        "print(\"=== Path Debugging ===\")\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n",
        "print(f\"Project root: {project_root}\")\n",
        "\n",
        "# Check if scripts directory exists\n",
        "scripts_path = os.path.join(project_root, 'scripts')\n",
        "print(f\"Scripts directory exists: {os.path.exists(scripts_path)}\")\n",
        "\n",
        "if os.path.exists(scripts_path):\n",
        "    print(\"Scripts directory contents:\")\n",
        "    for item in os.listdir(scripts_path):\n",
        "        print(f\"  - {item}\")\n",
        "\n",
        "# Check if model directory exists\n",
        "model_path = os.path.join(scripts_path, 'model')\n",
        "print(f\"Model directory exists: {os.path.exists(model_path)}\")\n",
        "\n",
        "if os.path.exists(model_path):\n",
        "    print(\"Model directory contents:\")\n",
        "    for item in os.listdir(model_path):\n",
        "        print(f\"  - {item}\")\n",
        "\n",
        "# Import project modules\n",
        "try:\n",
        "    from scripts.data_provider.graph_data_builder import build_pyg_data\n",
        "    from scripts.trainer.gat_trainer import train_gat_transformer_fusion\n",
        "    from scripts.model.doNET import GATWithTransformerFusion\n",
        "    from scripts.data_provider.data_preprocessing import prepare_train_test_anndata\n",
        "    print(\"âœ… All imports successful!\")\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ Import error: {e}\")\n",
        "    print(\"Trying alternative import method...\")\n",
        "    \n",
        "    # Alternative import method\n",
        "    import importlib.util\n",
        "    import sys\n",
        "    \n",
        "    # Add the project root to sys.path\n",
        "    project_root = os.path.dirname(os.getcwd())\n",
        "    if project_root not in sys.path:\n",
        "        sys.path.insert(0, project_root)\n",
        "    \n",
        "    # Try importing again\n",
        "    try:\n",
        "        from scripts.data_provider.graph_data_builder import build_pyg_data\n",
        "        from scripts.trainer.gat_trainer import train_gat_transformer_fusion\n",
        "        from scripts.model.doNET import GATWithTransformerFusion\n",
        "        from scripts.data_provider.data_preprocessing import prepare_train_test_anndata\n",
        "        print(\"âœ… Alternative imports successful!\")\n",
        "    except ImportError as e2:\n",
        "        print(f\"âŒ Alternative import also failed: {e2}\")\n",
        "        print(\"Please check that all required files exist and the project structure is correct.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test imports and model creation\n",
        "print(\"=== Testing Imports and Model Creation ===\")\n",
        "\n",
        "try:\n",
        "    # Test transformer models import\n",
        "    from scripts.model.transformer_models import TransformerMapping\n",
        "    print(\"âœ… Transformer models imported successfully\")\n",
        "    \n",
        "    # Test doNET import\n",
        "    from scripts.model.doNET import GATWithTransformerFusion, TransformerFusion\n",
        "    print(\"âœ… GATWithTransformerFusion imported successfully\")\n",
        "    \n",
        "    # Test model creation\n",
        "    print(\"\\n=== Testing Model Creation ===\")\n",
        "    \n",
        "    # Test TransformerMapping\n",
        "    transformer_mapping = TransformerMapping(\n",
        "        input_dim=50, \n",
        "        output_dim=10, \n",
        "        d_model=64\n",
        "    )\n",
        "    print(f\"âœ… TransformerMapping created: {transformer_mapping}\")\n",
        "    \n",
        "    # Test GATWithTransformerFusion\n",
        "    gat_transformer = GATWithTransformerFusion(\n",
        "        in_channels=50, \n",
        "        hidden_channels=32, \n",
        "        out_channels=10\n",
        "    )\n",
        "    print(f\"âœ… GATWithTransformerFusion created: {gat_transformer}\")\n",
        "    \n",
        "    print(\"\\nðŸŽ‰ All imports and model creation tests passed!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error during testing: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load and Preprocess Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load training data\n",
        "print(\"=== Loading Training Data ===\")\n",
        "\n",
        "# Load RNA and ADT data\n",
        "rna_adata = sc.read_h5ad(\"/projects/vanaja_lab/satya/Datasets/GSMControlRNA.h5ad\")\n",
        "adt_adata = sc.read_h5ad(\"/projects/vanaja_lab/satya/Datasets/ControlADT.h5ad\")\n",
        "\n",
        "print(f\"RNA data shape: {rna_adata.shape}\")\n",
        "print(f\"ADT data shape: {adt_adata.shape}\")\n",
        "\n",
        "# Ensure same number of cells\n",
        "if rna_adata.n_obs != adt_adata.n_obs:\n",
        "    print(\"Warning: RNA and ADT data have different number of cells\")\n",
        "    common_cells = rna_adata.obs_names.intersection(adt_adata.obs_names)\n",
        "    rna_adata = rna_adata[common_cells]\n",
        "    adt_adata = adt_adata[common_cells]\n",
        "    print(f\"Using {len(common_cells)} common cells\")\n",
        "\n",
        "print(f\"Final RNA data shape: {rna_adata.shape}\")\n",
        "print(f\"Final ADT data shape: {adt_adata.shape}\")\n",
        "\n",
        "# Basic preprocessing\n",
        "print(\"\\n=== Basic Preprocessing ===\")\n",
        "print(\"RNA data preprocessing...\")\n",
        "sc.pp.filter_genes(rna_adata, min_cells=10)\n",
        "sc.pp.filter_cells(rna_adata, min_genes=200)\n",
        "sc.pp.normalize_total(rna_adata, target_sum=1e4)\n",
        "sc.pp.log1p(rna_adata)\n",
        "sc.pp.highly_variable_genes(rna_adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
        "rna_adata.raw = rna_adata\n",
        "rna_adata = rna_adata[:, rna_adata.var.highly_variable]\n",
        "\n",
        "print(\"ADT data preprocessing...\")\n",
        "sc.pp.filter_genes(adt_adata, min_cells=10)\n",
        "sc.pp.filter_cells(adt_adata, min_genes=5)\n",
        "sc.pp.normalize_total(adt_adata, target_sum=1e4)\n",
        "sc.pp.log1p(adt_adata)\n",
        "\n",
        "print(f\"After preprocessing - RNA: {rna_adata.shape}, ADT: {adt_adata.shape}\")\n",
        "\n",
        "# Ensure same cells after preprocessing\n",
        "common_cells = rna_adata.obs_names.intersection(adt_adata.obs_names)\n",
        "rna_adata = rna_adata[common_cells]\n",
        "adt_adata = adt_adata[common_cells]\n",
        "\n",
        "print(f\"Final common cells: {len(common_cells)}\")\n",
        "print(\"âœ… Data loading and preprocessing complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Convert to PyTorch Geometric Format\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert AnnData to PyTorch Geometric format\n",
        "print(\"=== Converting to PyTorch Geometric Format ===\")\n",
        "\n",
        "# Convert RNA data\n",
        "print(\"Converting RNA data...\")\n",
        "rna_pyg_data = build_pyg_data(rna_adata)\n",
        "print(f\"RNA PyG data: {rna_pyg_data}\")\n",
        "\n",
        "# Convert ADT data\n",
        "print(\"Converting ADT data...\")\n",
        "adt_pyg_data = build_pyg_data(adt_adata)\n",
        "print(f\"ADT PyG data: {adt_pyg_data}\")\n",
        "\n",
        "# Verify data compatibility\n",
        "print(f\"\\n=== Data Compatibility Check ===\")\n",
        "print(f\"RNA nodes: {rna_pyg_data.num_nodes}\")\n",
        "print(f\"ADT nodes: {adt_pyg_data.num_nodes}\")\n",
        "print(f\"RNA features: {rna_pyg_data.x.shape[1]}\")\n",
        "print(f\"ADT features: {adt_pyg_data.x.shape[1]}\")\n",
        "print(f\"RNA edges: {rna_pyg_data.num_edges}\")\n",
        "print(f\"ADT edges: {adt_pyg_data.num_edges}\")\n",
        "\n",
        "if rna_pyg_data.num_nodes != adt_pyg_data.num_nodes:\n",
        "    print(\"âš ï¸  Warning: RNA and ADT data have different number of nodes!\")\n",
        "else:\n",
        "    print(\"âœ… RNA and ADT data have same number of nodes\")\n",
        "\n",
        "print(\"âœ… PyTorch Geometric conversion complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Initialize GATWithTransformerFusion Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the GATWithTransformerFusion model\n",
        "print(\"=== Initializing GATWithTransformerFusion Model ===\")\n",
        "\n",
        "# Get data dimensions\n",
        "rna_input_dim = rna_pyg_data.x.shape[1]\n",
        "adt_output_dim = adt_pyg_data.x.shape[1]\n",
        "\n",
        "print(f\"RNA input dimension: {rna_input_dim}\")\n",
        "print(f\"ADT output dimension: {adt_output_dim}\")\n",
        "\n",
        "# Model configuration\n",
        "model_config = {\n",
        "    'in_channels': rna_input_dim,\n",
        "    'hidden_channels': 64,\n",
        "    'out_channels': adt_output_dim,\n",
        "    'heads': 8,\n",
        "    'dropout': 0.6,\n",
        "    'nhead': 4,\n",
        "    'num_layers': 2\n",
        "}\n",
        "\n",
        "print(f\"Model configuration: {model_config}\")\n",
        "\n",
        "# Initialize model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = GATWithTransformerFusion(**model_config).to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "# Model architecture summary\n",
        "print(f\"\\n=== Model Architecture ===\")\n",
        "print(f\"GAT RNA Encoder: {rna_input_dim} -> {model_config['hidden_channels']} (2 layers)\")\n",
        "print(f\"Transformer Fusion: {model_config['hidden_channels']} dim, {model_config['nhead']} heads, {model_config['num_layers']} layers\")\n",
        "print(f\"GAT ADT Predictor: {model_config['hidden_channels']} -> {adt_output_dim} (1 layer)\")\n",
        "\n",
        "print(\"âœ… Model initialization complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the GATWithTransformerFusion model\n",
        "print(\"=== Training GATWithTransformerFusion Model ===\")\n",
        "\n",
        "# Training parameters\n",
        "training_config = {\n",
        "    'epochs': 100,\n",
        "    'use_cpu_fallback': True,  # Set to False if you have sufficient GPU memory\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "print(f\"Training configuration: {training_config}\")\n",
        "\n",
        "# Start training\n",
        "start_time = datetime.now()\n",
        "print(f\"Training started at: {start_time}\")\n",
        "\n",
        "# Train the model\n",
        "trained_model, rna_data_with_masks, adt_data_with_masks = train_gat_transformer_fusion(\n",
        "    rna_data=rna_pyg_data,\n",
        "    adt_data=adt_pyg_data,\n",
        "    **training_config\n",
        ")\n",
        "\n",
        "end_time = datetime.now()\n",
        "training_duration = end_time - start_time\n",
        "\n",
        "print(f\"\\n=== Training Complete ===\")\n",
        "print(f\"Training finished at: {end_time}\")\n",
        "print(f\"Total training time: {training_duration}\")\n",
        "print(f\"Training time per epoch: {training_duration / training_config['epochs']}\")\n",
        "\n",
        "print(\"âœ… Model training complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Evaluate Model Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate model performance\n",
        "print(\"=== Model Performance Evaluation ===\")\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "# Make predictions on test set\n",
        "trained_model.eval()\n",
        "with torch.no_grad():\n",
        "    test_predictions, test_fused_embeddings = trained_model(\n",
        "        x=rna_data_with_masks.x,\n",
        "        edge_index_rna=rna_data_with_masks.edge_index,\n",
        "        edge_index_adt=adt_data_with_masks.edge_index\n",
        "    )\n",
        "\n",
        "# Get test set predictions and ground truth\n",
        "test_mask = rna_data_with_masks.test_mask\n",
        "y_true = adt_data_with_masks.x[test_mask].cpu().numpy()\n",
        "y_pred = test_predictions[test_mask].cpu().numpy()\n",
        "\n",
        "print(f\"Test set size: {y_true.shape[0]} cells\")\n",
        "print(f\"Prediction shape: {y_pred.shape}\")\n",
        "\n",
        "# Calculate metrics\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "print(f\"\\n=== Performance Metrics ===\")\n",
        "print(f\"MSE: {mse:.6f}\")\n",
        "print(f\"RÂ² Score: {r2:.4f}\")\n",
        "\n",
        "# Calculate per-marker correlations\n",
        "pearson_corrs = []\n",
        "spearman_corrs = []\n",
        "\n",
        "for i in range(y_true.shape[1]):\n",
        "    if y_true[:, i].std() > 0 and y_pred[:, i].std() > 0:\n",
        "        pearson_r, _ = pearsonr(y_true[:, i], y_pred[:, i])\n",
        "        spearman_r, _ = spearmanr(y_true[:, i], y_pred[:, i])\n",
        "        pearson_corrs.append(pearson_r)\n",
        "        spearman_corrs.append(spearman_r)\n",
        "\n",
        "mean_pearson = np.mean(pearson_corrs)\n",
        "mean_spearman = np.mean(spearman_corrs)\n",
        "\n",
        "print(f\"Mean Pearson Correlation: {mean_pearson:.4f}\")\n",
        "print(f\"Mean Spearman Correlation: {mean_spearman:.4f}\")\n",
        "\n",
        "# Show top and bottom performing markers\n",
        "if len(pearson_corrs) > 0:\n",
        "    marker_names = adt_adata.var_names[:len(pearson_corrs)]\n",
        "    corr_df = pd.DataFrame({\n",
        "        'marker': marker_names,\n",
        "        'pearson': pearson_corrs,\n",
        "        'spearman': spearman_corrs\n",
        "    })\n",
        "    \n",
        "    print(f\"\\n=== Top 5 Performing Markers (Pearson) ===\")\n",
        "    top_markers = corr_df.nlargest(5, 'pearson')\n",
        "    for _, row in top_markers.iterrows():\n",
        "        print(f\"  {row['marker']}: {row['pearson']:.4f}\")\n",
        "    \n",
        "    print(f\"\\n=== Bottom 5 Performing Markers (Pearson) ===\")\n",
        "    bottom_markers = corr_df.nsmallest(5, 'pearson')\n",
        "    for _, row in bottom_markers.iterrows():\n",
        "        print(f\"  {row['marker']}: {row['pearson']:.4f}\")\n",
        "\n",
        "print(\"âœ… Performance evaluation complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Visualize Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create visualizations\n",
        "print(\"=== Creating Visualizations ===\")\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('default')\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "fig.suptitle('GATWithTransformerFusion Training Results', fontsize=16)\n",
        "\n",
        "# 1. Prediction vs Ground Truth scatter plot (sample of markers)\n",
        "ax1 = axes[0, 0]\n",
        "sample_markers = min(5, y_true.shape[1])\n",
        "for i in range(sample_markers):\n",
        "    ax1.scatter(y_true[:, i], y_pred[:, i], alpha=0.6, s=10, label=f'Marker {i+1}')\n",
        "ax1.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)\n",
        "ax1.set_xlabel('Ground Truth')\n",
        "ax1.set_ylabel('Predicted')\n",
        "ax1.set_title('Prediction vs Ground Truth')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Correlation distribution\n",
        "ax2 = axes[0, 1]\n",
        "ax2.hist(pearson_corrs, bins=20, alpha=0.7, edgecolor='black')\n",
        "ax2.axvline(mean_pearson, color='red', linestyle='--', label=f'Mean: {mean_pearson:.3f}')\n",
        "ax2.set_xlabel('Pearson Correlation')\n",
        "ax2.set_ylabel('Frequency')\n",
        "ax2.set_title('Correlation Distribution')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Top performing markers\n",
        "ax3 = axes[0, 2]\n",
        "if len(pearson_corrs) > 0:\n",
        "    top_10_markers = corr_df.nlargest(10, 'pearson')\n",
        "    ax3.barh(range(len(top_10_markers)), top_10_markers['pearson'])\n",
        "    ax3.set_yticks(range(len(top_10_markers)))\n",
        "    ax3.set_yticklabels(top_10_markers['marker'], fontsize=8)\n",
        "    ax3.set_xlabel('Pearson Correlation')\n",
        "    ax3.set_title('Top 10 Performing Markers')\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Residuals plot\n",
        "ax4 = axes[1, 0]\n",
        "residuals = y_true - y_pred\n",
        "ax4.scatter(y_pred, residuals, alpha=0.6, s=10)\n",
        "ax4.axhline(y=0, color='red', linestyle='--')\n",
        "ax4.set_xlabel('Predicted Values')\n",
        "ax4.set_ylabel('Residuals')\n",
        "ax4.set_title('Residuals Plot')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "# 5. Fused embeddings visualization (PCA)\n",
        "ax5 = axes[1, 1]\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "fused_embeddings_2d = pca.fit_transform(test_fused_embeddings[test_mask].cpu().numpy())\n",
        "ax5.scatter(fused_embeddings_2d[:, 0], fused_embeddings_2d[:, 1], alpha=0.6, s=10)\n",
        "ax5.set_xlabel('PC1')\n",
        "ax5.set_ylabel('PC2')\n",
        "ax5.set_title('Fused Embeddings (PCA)')\n",
        "ax5.grid(True, alpha=0.3)\n",
        "\n",
        "# 6. Performance summary\n",
        "ax6 = axes[1, 2]\n",
        "ax6.axis('off')\n",
        "summary_text = f\"\"\"\n",
        "Performance Summary:\n",
        "\n",
        "MSE: {mse:.6f}\n",
        "RÂ² Score: {r2:.4f}\n",
        "Mean Pearson: {mean_pearson:.4f}\n",
        "Mean Spearman: {mean_spearman:.4f}\n",
        "\n",
        "Model Architecture:\n",
        "â€¢ GAT RNA Encoder: 2 layers\n",
        "â€¢ Transformer Fusion: 2 layers\n",
        "â€¢ GAT ADT Predictor: 1 layer\n",
        "\n",
        "Training:\n",
        "â€¢ Epochs: {training_config['epochs']}\n",
        "â€¢ Parameters: {total_params:,}\n",
        "â€¢ Device: {device}\n",
        "\"\"\"\n",
        "ax6.text(0.1, 0.9, summary_text, transform=ax6.transAxes, fontsize=10,\n",
        "         verticalalignment='top', fontfamily='monospace',\n",
        "         bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ… Visualizations complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7.1 UMAP Visualizations of Embeddings and Markers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import umap\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "print(\"=== Creating UMAP Visualizations ===\")\n",
        "\n",
        "# Get embeddings and predictions\n",
        "with torch.no_grad():\n",
        "    predictions, fused_embeddings = trained_model(\n",
        "        rna_data_with_masks.x,\n",
        "        rna_data_with_masks.edge_index\n",
        "    )\n",
        "\n",
        "# Convert to numpy arrays\n",
        "embeddings_np = fused_embeddings.cpu().numpy()\n",
        "predictions_np = predictions.cpu().numpy()\n",
        "true_values_np = adt_data_with_masks.x.cpu().numpy()\n",
        "\n",
        "# Standardize the embeddings\n",
        "scaler = StandardScaler()\n",
        "embeddings_scaled = scaler.fit_transform(embeddings_np)\n",
        "\n",
        "# Create UMAP reducer\n",
        "reducer = umap.UMAP(\n",
        "    n_neighbors=15,\n",
        "    min_dist=0.1,\n",
        "    n_components=2,\n",
        "    metric='euclidean',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Get UMAP embeddings\n",
        "umap_embeddings = reducer.fit_transform(embeddings_scaled)\n",
        "\n",
        "# Create figure with multiple subplots\n",
        "n_markers = min(6, true_values_np.shape[1])  # Show up to 6 markers\n",
        "fig = plt.figure(figsize=(20, 15))\n",
        "fig.suptitle('UMAP Visualizations of Embeddings and Markers', fontsize=16)\n",
        "\n",
        "# Plot UMAP colored by different markers\n",
        "for idx in range(n_markers):\n",
        "    # True Values\n",
        "    plt.subplot(3, n_markers, idx + 1)\n",
        "    scatter = plt.scatter(\n",
        "        umap_embeddings[:, 0],\n",
        "        umap_embeddings[:, 1],\n",
        "        c=true_values_np[:, idx],\n",
        "        cmap='viridis',\n",
        "        s=5,\n",
        "        alpha=0.7\n",
        "    )\n",
        "    plt.colorbar(scatter)\n",
        "    plt.title(f'True ADT Marker {idx+1}')\n",
        "    plt.xlabel('UMAP1')\n",
        "    plt.ylabel('UMAP2')\n",
        "    \n",
        "    # Predicted Values\n",
        "    plt.subplot(3, n_markers, n_markers + idx + 1)\n",
        "    scatter = plt.scatter(\n",
        "        umap_embeddings[:, 0],\n",
        "        umap_embeddings[:, 1],\n",
        "        c=predictions_np[:, idx],\n",
        "        cmap='viridis',\n",
        "        s=5,\n",
        "        alpha=0.7\n",
        "    )\n",
        "    plt.colorbar(scatter)\n",
        "    plt.title(f'Predicted ADT Marker {idx+1}')\n",
        "    plt.xlabel('UMAP1')\n",
        "    plt.ylabel('UMAP2')\n",
        "    \n",
        "    # Difference (Error)\n",
        "    plt.subplot(3, n_markers, 2*n_markers + idx + 1)\n",
        "    scatter = plt.scatter(\n",
        "        umap_embeddings[:, 0],\n",
        "        umap_embeddings[:, 1],\n",
        "        c=np.abs(true_values_np[:, idx] - predictions_np[:, idx]),\n",
        "        cmap='viridis',\n",
        "        s=5,\n",
        "        alpha=0.7\n",
        "    )\n",
        "    plt.colorbar(scatter)\n",
        "    plt.title(f'Prediction Error Marker {idx+1}')\n",
        "    plt.xlabel('UMAP1')\n",
        "    plt.ylabel('UMAP2')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ… UMAP visualizations complete!\")\n",
        "\n",
        "# Print correlation statistics for each marker\n",
        "print(\"\\n=== Marker-wise Statistics ===\")\n",
        "for idx in range(n_markers):\n",
        "    true_vals = true_values_np[:, idx]\n",
        "    pred_vals = predictions_np[:, idx]\n",
        "    pearson_r = pearsonr(true_vals, pred_vals)[0]\n",
        "    spearman_r = spearmanr(true_vals, pred_vals)[0]\n",
        "    mse = mean_squared_error(true_vals, pred_vals)\n",
        "    \n",
        "    print(f\"\\nMarker {idx+1}:\")\n",
        "    print(f\"Pearson correlation: {pearson_r:.4f}\")\n",
        "    print(f\"Spearman correlation: {spearman_r:.4f}\")\n",
        "    print(f\"MSE: {mse:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save Trained Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "print(\"=== Saving Trained Model ===\")\n",
        "\n",
        "# Create save directory\n",
        "save_dir = \"trained_models\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Generate timestamp for unique filename\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "model_filename = f\"gat_transformer_fusion_{timestamp}.pth\"\n",
        "model_path = os.path.join(save_dir, model_filename)\n",
        "\n",
        "# Save model checkpoint\n",
        "checkpoint = {\n",
        "    'model_state_dict': trained_model.state_dict(),\n",
        "    'model_config': model_config,\n",
        "    'training_config': training_config,\n",
        "    'performance_metrics': {\n",
        "        'mse': mse,\n",
        "        'r2_score': r2,\n",
        "        'mean_pearson': mean_pearson,\n",
        "        'mean_spearman': mean_spearman\n",
        "    },\n",
        "    'data_info': {\n",
        "        'rna_input_dim': rna_input_dim,\n",
        "        'adt_output_dim': adt_output_dim,\n",
        "        'num_nodes': rna_pyg_data.num_nodes,\n",
        "        'num_edges': rna_pyg_data.num_edges\n",
        "    },\n",
        "    'training_time': str(training_duration),\n",
        "    'timestamp': timestamp\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, model_path)\n",
        "\n",
        "print(f\"Model saved to: {model_path}\")\n",
        "print(f\"Checkpoint contains:\")\n",
        "for key in checkpoint.keys():\n",
        "    print(f\"  â€¢ {key}\")\n",
        "\n",
        "# Also save a simple state dict for easy loading\n",
        "simple_model_path = os.path.join(save_dir, f\"gat_transformer_fusion_simple_{timestamp}.pth\")\n",
        "torch.save(trained_model.state_dict(), simple_model_path)\n",
        "print(f\"Simple model state dict saved to: {simple_model_path}\")\n",
        "\n",
        "print(\"âœ… Model saving complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Make Predictions on New Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to make predictions on new data\n",
        "def predict_with_gat_transformer_fusion(model, rna_adata, device=None):\n",
        "    \"\"\"\n",
        "    Make predictions using trained GATWithTransformerFusion model\n",
        "    \n",
        "    Args:\n",
        "        model: Trained GATWithTransformerFusion model\n",
        "        rna_adata: AnnData object with RNA data\n",
        "        device: Device to use for inference\n",
        "    \n",
        "    Returns:\n",
        "        predicted_adt_embeddings, fused_embeddings\n",
        "    \"\"\"\n",
        "    \n",
        "    print(\"=== Making Predictions with GATWithTransformerFusion ===\")\n",
        "    \n",
        "    if device is None:\n",
        "        device = next(model.parameters()).device\n",
        "    \n",
        "    # Convert to PyTorch Geometric format\n",
        "    rna_pyg_data = build_pyg_data(rna_adata)\n",
        "    rna_pyg_data = rna_pyg_data.to(device)\n",
        "    \n",
        "    print(f\"Input RNA data shape: {rna_adata.shape}\")\n",
        "    print(f\"PyG data: {rna_pyg_data}\")\n",
        "    \n",
        "    # Make predictions\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predicted_adt, fused_embeddings = model(\n",
        "            x=rna_pyg_data.x,\n",
        "            edge_index_rna=rna_pyg_data.edge_index\n",
        "        )\n",
        "    \n",
        "    # Convert to numpy\n",
        "    predicted_adt_np = predicted_adt.cpu().numpy()\n",
        "    fused_embeddings_np = fused_embeddings.cpu().numpy()\n",
        "    \n",
        "    print(f\"Predicted ADT shape: {predicted_adt_np.shape}\")\n",
        "    print(f\"Fused embeddings shape: {fused_embeddings_np.shape}\")\n",
        "    \n",
        "    return predicted_adt_np, fused_embeddings_np\n",
        "\n",
        "# Example: Make predictions on the same data (for demonstration)\n",
        "print(\"Making predictions on training data (for demonstration)...\")\n",
        "demo_predictions, demo_fused = predict_with_gat_transformer_fusion(trained_model, rna_adata)\n",
        "\n",
        "print(f\"\\n=== Prediction Summary ===\")\n",
        "print(f\"Predicted ADT embeddings shape: {demo_predictions.shape}\")\n",
        "print(f\"Fused embeddings shape: {demo_fused.shape}\")\n",
        "print(f\"Predicted ADT range: [{demo_predictions.min():.4f}, {demo_predictions.max():.4f}]\")\n",
        "print(f\"Fused embeddings range: [{demo_fused.min():.4f}, {demo_fused.max():.4f}]\")\n",
        "\n",
        "print(\"âœ… Predictions complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Load Saved Model (Example)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: How to load a saved model\n",
        "def load_gat_transformer_fusion_model(model_path, device=None):\n",
        "    \"\"\"\n",
        "    Load a saved GATWithTransformerFusion model\n",
        "    \n",
        "    Args:\n",
        "        model_path: Path to the saved model checkpoint\n",
        "        device: Device to load the model on\n",
        "    \n",
        "    Returns:\n",
        "        loaded_model, checkpoint_info\n",
        "    \"\"\"\n",
        "    \n",
        "    print(f\"=== Loading GATWithTransformerFusion Model ===\")\n",
        "    print(f\"Loading from: {model_path}\")\n",
        "    \n",
        "    if device is None:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "    \n",
        "    # Extract model configuration\n",
        "    model_config = checkpoint['model_config']\n",
        "    print(f\"Model configuration: {model_config}\")\n",
        "    \n",
        "    # Initialize model\n",
        "    model = GATWithTransformerFusion(**model_config).to(device)\n",
        "    \n",
        "    # Load state dict\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "    \n",
        "    print(f\"Model loaded successfully on {device}\")\n",
        "    \n",
        "    # Print checkpoint info\n",
        "    print(f\"\\n=== Checkpoint Information ===\")\n",
        "    for key, value in checkpoint.items():\n",
        "        if key != 'model_state_dict':\n",
        "            print(f\"  {key}: {value}\")\n",
        "    \n",
        "    return model, checkpoint\n",
        "\n",
        "# Example usage (commented out since we already have the model loaded)\n",
        "\"\"\"\n",
        "# Load the model we just saved\n",
        "loaded_model, checkpoint_info = load_gat_transformer_fusion_model(model_path)\n",
        "\n",
        "# Make predictions with loaded model\n",
        "new_predictions, new_fused = predict_with_gat_transformer_fusion(loaded_model, rna_adata)\n",
        "\n",
        "print(\"âœ… Model loading example complete!\")\n",
        "\"\"\"\n",
        "\n",
        "print(\"âœ… Model loading function ready!\")\n",
        "print(\"Uncomment the example code above to test loading the saved model.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Summary and Next Steps\n",
        "\n",
        "### What We've Accomplished:\n",
        "1. âœ… **Loaded and preprocessed** RNA and ADT data\n",
        "2. âœ… **Converted data** to PyTorch Geometric format\n",
        "3. âœ… **Initialized** GATWithTransformerFusion model\n",
        "4. âœ… **Trained** the model with end-to-end optimization\n",
        "5. âœ… **Evaluated** performance with comprehensive metrics\n",
        "6. âœ… **Visualized** results with multiple plots\n",
        "7. âœ… **Saved** the trained model with full checkpoint\n",
        "8. âœ… **Created** prediction functions for new data\n",
        "9. âœ… **Provided** model loading examples\n",
        "\n",
        "### Key Advantages of GATWithTransformerFusion:\n",
        "- **End-to-end training**: Single model for RNAâ†’ADT mapping\n",
        "- **Graph structure preservation**: Maintains graph relationships throughout\n",
        "- **Transformer benefits**: Self-attention for better feature fusion\n",
        "- **Unified architecture**: Combines GAT and Transformer in one model\n",
        "\n",
        "### Performance Metrics:\n",
        "- **MSE**: Measure of prediction accuracy\n",
        "- **RÂ² Score**: Explained variance\n",
        "- **Pearson/Spearman Correlations**: Per-marker performance\n",
        "- **Training time**: Efficiency metrics\n",
        "\n",
        "### Next Steps:\n",
        "1. **Compare** with existing GAT + Transformer pipeline\n",
        "2. **Tune hyperparameters** for better performance\n",
        "3. **Test on different datasets** for generalization\n",
        "4. **Integrate** with existing workflow\n",
        "5. **Deploy** for production use\n",
        "\n",
        "### Usage in Other Notebooks:\n",
        "```python\n",
        "# Load the trained model\n",
        "from scripts.trainer.gat_trainer import train_gat_transformer_fusion\n",
        "from scripts.model.doNET import GATWithTransformerFusion\n",
        "\n",
        "# Train new model\n",
        "trained_model, rna_data, adt_data = train_gat_transformer_fusion(\n",
        "    rna_data=rna_pyg_data,\n",
        "    adt_data=adt_pyg_data,\n",
        "    epochs=100\n",
        ")\n",
        "\n",
        "# Make predictions\n",
        "predicted_adt, fused_embeddings = predict_with_gat_transformer_fusion(\n",
        "    trained_model, new_rna_adata\n",
        ")\n",
        "```\n",
        "\n",
        "**ðŸŽ‰ GATWithTransformerFusion training pipeline is now ready for use!**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
