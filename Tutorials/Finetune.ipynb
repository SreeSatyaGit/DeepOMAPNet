{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d200d0-fb37-4e06-b342-5dd4b7107a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Setup Information ===\n",
      "Current directory: /projects/vanaja_lab/satya/DeepOMAPNet/Tutorials\n",
      "Project root: /projects/vanaja_lab/satya/DeepOMAPNet\n",
      "Python version: 3.12.12 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 20:16:04) [GCC 11.2.0]\n",
      "PyTorch version: 2.9.0+cu128\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA H200\n",
      "CUDA memory: 150.1 GB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plta\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to Python path\n",
    "current_dir = os.getcwd()\n",
    "project_root = os.path.dirname(current_dir)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(\"=== Setup Information ===\")\n",
    "print(f\"Current directory: {current_dir}\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e910c42c-f6d1-4ef4-bc0f-2ebbe1f0dff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to Python path:\n",
      "- Current directory: /projects/vanaja_lab/satya/DeepOMAPNet/Tutorials\n",
      "- Project root: /projects/vanaja_lab/satya/DeepOMAPNet\n",
      "- Scripts directory exists: True\n",
      "- Scripts/data_provider exists: True\n",
      "Module imports successful!\n"
     ]
    }
   ],
   "source": [
    "import sys, os, importlib\n",
    "\n",
    "# --- Paths ---\n",
    "current_dir = os.getcwd()  # This will be .../DeepOMAPNet/Notebooks\n",
    "project_root = os.path.dirname(current_dir)  # This will be .../DeepOMAPNet\n",
    "\n",
    "# Add project root to Python path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(\"Added to Python path:\")\n",
    "print(f\"- Current directory: {current_dir}\")\n",
    "print(f\"- Project root: {project_root}\")\n",
    "print(f\"- Scripts directory exists: {os.path.exists(os.path.join(project_root, 'scripts'))}\")\n",
    "print(f\"- Scripts/data_provider exists: {os.path.exists(os.path.join(project_root, 'scripts', 'data_provider'))}\")\n",
    "\n",
    "# Clear any cached imports\n",
    "importlib.invalidate_caches()\n",
    "\n",
    "# --- Import modules (module-style, not from ... import ...) ---\n",
    "import scripts.data_provider.data_preprocessing as data_preprocessing\n",
    "import scripts.data_provider.graph_data_builder as graph_data_builder\n",
    "import scripts.model.doNET as doNET\n",
    "import scripts.trainer.gat_trainer as gat_trainer\n",
    "\n",
    "print(\"Module imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de6ddbfa-fe71-4a3e-9ce0-883bb0190a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading Training Data ===\n",
      "All sample IDs in gene data: ['AML0612' 'AML3762' 'AML3133' 'AML2910' 'AML3050' 'AML2451' 'AML056'\n",
      " 'AML073' 'AML055' 'AML048' 'AML052' 'AML2123' 'AML1371' 'AML4340'\n",
      " 'AML4897' 'AML051' 'AML0693' 'AML3948' 'AML3730' 'AML0160' 'AML0310'\n",
      " 'AML0361' 'AML038' 'AML008' 'AML043' 'AML028' 'AML006' 'AML025' 'AML003'\n",
      " 'AML012' 'AML005' 'AML0048' 'AML022' 'AML0024' 'AML009' 'AML026' 'AML001'\n",
      " 'AML0114' 'Control4' 'Control2' 'Control1' 'Control3' 'Control5'\n",
      " 'Control0004' 'Control0058' 'Control0082' 'Control4003' 'Control0005']\n",
      "AML 80% train: ['AML0024', 'AML001', 'AML3050', 'AML4340', 'AML005', 'AML006', 'AML056', 'AML025', 'AML043', 'AML051', 'AML3948', 'AML055', 'AML0693', 'AML1371', 'AML0160', 'AML048', 'AML022', 'AML0612', 'AML028', 'AML2451', 'AML2123', 'AML3762', 'AML0114', 'AML0361', 'AML3133', 'AML012', 'AML026', 'AML2910', 'AML009', 'AML008', 'AML0048']\n",
      "AML 20% test: ['AML052', 'AML038', 'AML3730', 'AML0310', 'AML073', 'AML4897', 'AML003']\n",
      "Control 80% train: ['Control4003', 'Control1', 'Control0004', 'Control0082', 'Control3', 'Control2', 'Control0005', 'Control4']\n",
      "Control 20% test: ['Control5', 'Control0058']\n",
      "Train cells: 158179 | Test cells: 46922\n",
      "\n",
      "============================================================\n",
      "NORMALIZING PROTEIN (ADT) DATA\n",
      "============================================================\n",
      "\n",
      "Step 1: Applying CLR normalization to training protein data...\n",
      "  CLR normalization complete. Shape: (158179, 279)\n",
      "\n",
      "Step 2: Applying z-score normalization to training protein data...\n",
      "  Z-score normalization complete.\n",
      "  Mean of feature means: 0.0000\n",
      "  Mean of feature stds: 0.5178\n",
      "\n",
      "Step 3: Applying CLR normalization to test protein data...\n",
      "  CLR normalization complete. Shape: (46922, 279)\n",
      "\n",
      "Step 4: Applying z-score normalization to test protein data (using training statistics)...\n",
      "  Z-score normalization complete.\n",
      "  Test data normalized using training statistics for consistency.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "print(\"=== Loading Training Data ===\")\n",
    "# Load RNA and ADT data\n",
    "rna_adata = sc.read_h5ad(\"/projects/vanaja_lab/satya/Datasets/GSMControlRNA.h5ad\")\n",
    "adt_adata = sc.read_h5ad(\"/projects/vanaja_lab/satya/Datasets/ControlADT.h5ad\")\n",
    "\n",
    "\n",
    "# Load the preprocessed data\n",
    "from scripts.data_provider.data_preprocessing import prepare_train_test_anndata\n",
    "data = prepare_train_test_anndata()\n",
    "rna_adata = data[0]  # RNA data\n",
    "rna_test = data[1]\n",
    "adt_adata = data[2]   # ADT data\n",
    "adt_test = data[3]\n",
    "\n",
    "sc.pp.highly_variable_genes(rna_adata, n_top_genes=2000, flavor='cell_ranger')\n",
    "# Subset by highly variable genes\n",
    "hvg_mask = rna_adata.var['highly_variable']\n",
    "rna_adata = rna_adata[:, hvg_mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2befa42-e495-4566-a520-8e58bfdbdda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Subsampling Dataset ===\n",
      "Target subsample size: 50000\n",
      "Train subsample: 40000\n",
      "Test subsample: 10000\n",
      "Original train RNA: (158179, 2000)\n",
      "Original train ADT: (158179, 279)\n",
      "Original test RNA: (46922, 36601)\n",
      "Original test ADT: (46922, 279)\n",
      "Original - AML train: 118224, Normal train: 39955\n",
      "Original - AML test: 36633, Normal test: 10289\n",
      "Subsample - AML train: 29880, Normal train: 10120\n",
      "Subsample - AML test: 7470, Normal test: 2530\n",
      "Final subsample - Train: 40000, Test: 10000\n",
      "Subsampled train RNA: (40000, 2000)\n",
      "Subsampled train ADT: (40000, 279)\n",
      "Subsampled test RNA: (10000, 36601)\n",
      "Subsampled test ADT: (10000, 279)\n",
      "Class balance - Train: AML 29880 (74.7%), Normal 10120\n",
      "Class balance - Test: AML 7470 (74.7%), Normal 2530\n",
      "\n",
      "=== Ready for GPU Training ===\n",
      "Use rna_adata_subset and adt_adata_subset for training\n",
      "Use rna_test_subset and adt_test_subset for testing\n"
     ]
    }
   ],
   "source": [
    "# Subsampling configuration\n",
    "SUBSAMPLE_SIZE = 50000  # Adjust based on your GPU memory\n",
    "TRAIN_SUBSAMPLE_SIZE = int(SUBSAMPLE_SIZE * 0.8)  # 40,000 train\n",
    "TEST_SUBSAMPLE_SIZE = int(SUBSAMPLE_SIZE * 0.2)   # 10,000 test\n",
    "\n",
    "print(f\"=== Subsampling Dataset ===\")\n",
    "print(f\"Target subsample size: {SUBSAMPLE_SIZE}\")\n",
    "print(f\"Train subsample: {TRAIN_SUBSAMPLE_SIZE}\")\n",
    "print(f\"Test subsample: {TEST_SUBSAMPLE_SIZE}\")\n",
    "\n",
    "# Check original sizes\n",
    "print(f\"Original train RNA: {rna_adata.shape}\")\n",
    "print(f\"Original train ADT: {adt_adata.shape}\")\n",
    "print(f\"Original test RNA: {rna_test.shape}\")\n",
    "print(f\"Original test ADT: {adt_test.shape}\")\n",
    "\n",
    "# Get cell indices for each class in train data\n",
    "aml_train_indices = []\n",
    "normal_train_indices = []\n",
    "\n",
    "# Separate train indices by class\n",
    "for i, sample_id in enumerate(rna_adata.obs['samples']):\n",
    "    if sample_id.startswith('AML'):\n",
    "        aml_train_indices.append(i)\n",
    "    else:  # Control samples\n",
    "        normal_train_indices.append(i)\n",
    "\n",
    "# Get cell indices for each class in test data\n",
    "aml_test_indices = []\n",
    "normal_test_indices = []\n",
    "\n",
    "# Separate test indices by class\n",
    "for i, sample_id in enumerate(rna_test.obs['samples']):\n",
    "    if sample_id.startswith('AML'):\n",
    "        aml_test_indices.append(i)\n",
    "    else:  # Control samples\n",
    "        normal_test_indices.append(i)\n",
    "\n",
    "print(f\"Original - AML train: {len(aml_train_indices)}, Normal train: {len(normal_train_indices)}\")\n",
    "print(f\"Original - AML test: {len(aml_test_indices)}, Normal test: {len(normal_test_indices)}\")\n",
    "\n",
    "# Calculate subsample sizes maintaining class balance\n",
    "aml_train_subsize = int(TRAIN_SUBSAMPLE_SIZE * 0.747)  # 74.7% AML\n",
    "normal_train_subsize = TRAIN_SUBSAMPLE_SIZE - aml_train_subsize\n",
    "aml_test_subsize = int(TEST_SUBSAMPLE_SIZE * 0.747)\n",
    "normal_test_subsize = TEST_SUBSAMPLE_SIZE - aml_test_subsize\n",
    "\n",
    "print(f\"Subsample - AML train: {aml_train_subsize}, Normal train: {normal_train_subsize}\")\n",
    "print(f\"Subsample - AML test: {aml_test_subsize}, Normal test: {normal_test_subsize}\")\n",
    "\n",
    "# Randomly sample indices\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# Sample train indices\n",
    "aml_train_subset = np.random.choice(aml_train_indices, aml_train_subsize, replace=False)\n",
    "normal_train_subset = np.random.choice(normal_train_indices, normal_train_subsize, replace=False)\n",
    "\n",
    "# Sample test indices\n",
    "aml_test_subset = np.random.choice(aml_test_indices, aml_test_subsize, replace=False)\n",
    "normal_test_subset = np.random.choice(normal_test_indices, normal_test_subsize, replace=False)\n",
    "\n",
    "# Combine train and test indices\n",
    "train_subset_indices = np.concatenate([aml_train_subset, normal_train_subset])\n",
    "test_subset_indices = np.concatenate([aml_test_subset, normal_test_subset])\n",
    "\n",
    "print(f\"Final subsample - Train: {len(train_subset_indices)}, Test: {len(test_subset_indices)}\")\n",
    "\n",
    "# Create subsampled data using your existing split\n",
    "rna_adata_subset = rna_adata[train_subset_indices].copy()\n",
    "adt_adata_subset = adt_adata[train_subset_indices].copy()\n",
    "\n",
    "# Create test data using your existing split\n",
    "rna_test_subset = rna_test[test_subset_indices].copy()\n",
    "adt_test_subset = adt_test[test_subset_indices].copy()\n",
    "\n",
    "print(f\"Subsampled train RNA: {rna_adata_subset.shape}\")\n",
    "print(f\"Subsampled train ADT: {adt_adata_subset.shape}\")\n",
    "print(f\"Subsampled test RNA: {rna_test_subset.shape}\")\n",
    "print(f\"Subsampled test ADT: {adt_test_subset.shape}\")\n",
    "\n",
    "# Verify class balance\n",
    "aml_count_train = sum(1 for sample in rna_adata_subset.obs['samples'] if sample.startswith('AML'))\n",
    "normal_count_train = len(rna_adata_subset) - aml_count_train\n",
    "aml_count_test = sum(1 for sample in rna_test_subset.obs['samples'] if sample.startswith('AML'))\n",
    "normal_count_test = len(rna_test_subset) - aml_count_test\n",
    "\n",
    "print(f\"Class balance - Train: AML {aml_count_train} ({aml_count_train/len(rna_adata_subset)*100:.1f}%), Normal {normal_count_train}\")\n",
    "print(f\"Class balance - Test: AML {aml_count_test} ({aml_count_test/len(rna_test_subset)*100:.1f}%), Normal {normal_count_test}\")\n",
    "\n",
    "# Now use the subsampled data for training\n",
    "print(f\"\\n=== Ready for GPU Training ===\")\n",
    "print(f\"Use rna_adata_subset and adt_adata_subset for training\")\n",
    "print(f\"Use rna_test_subset and adt_test_subset for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0878161-8f05-4527-906f-7bb7cbaaf075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining RNA data shape: (110673, 2000)\n",
      "Remaining ADT data shape: (110673, 279)\n"
     ]
    }
   ],
   "source": [
    "# Get all indices from the original dataset\n",
    "all_indices = np.arange(rna_adata.n_obs)\n",
    "\n",
    "# Combine the subsampled indices (train + test)\n",
    "subsample_indices = np.concatenate([train_subset_indices, test_subset_indices])\n",
    "\n",
    "# Identify the remaining indices (not used in the 50k subsample)\n",
    "remaining_indices = np.setdiff1d(all_indices, subsample_indices)\n",
    "\n",
    "# Create new AnnData objects for the remaining portions\n",
    "rna_adata_remaining = rna_adata[remaining_indices].copy()\n",
    "adt_adata_remaining = adt_adata[remaining_indices].copy()\n",
    "\n",
    "\n",
    "\n",
    "# Check shapes of remaining datasets\n",
    "print(f\"Remaining RNA data shape: {rna_adata_remaining.shape}\")\n",
    "print(f\"Remaining ADT data shape: {adt_adata_remaining.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebcf8344-c294-4983-b5a4-a12bc4d0301d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Converting to PyTorch Geometric Format ===\n",
      "Converting RNA data...\n",
      "build_pyg_data called with use_pca=True\n",
      "Input adata shape: (110673, 2000)\n",
      "Available obsm keys: ['X_integrated.cca', 'X_pca', 'X_umap', 'X_umap.unintegrated']\n",
      "Computing PCA with exactly 50 components...\n",
      "PCA computed, shape: (110673, 50)\n",
      "Computing neighbor graph first...\n",
      "Computing leiden clusters first...\n",
      "Using PCA features, shape: (110673, 50)\n",
      "RNA PyG data: Data(x=[110673, 50], edge_index=[2, 1265303], y=[110673])\n",
      "Converting ADT data...\n",
      "build_pyg_data called with use_pca=True\n",
      "Input adata shape: (110673, 279)\n",
      "Available obsm keys: []\n",
      "Computing PCA with exactly 50 components...\n",
      "PCA computed, shape: (110673, 50)\n",
      "Computing neighbor graph first...\n",
      "Computing leiden clusters first...\n",
      "Using PCA features, shape: (110673, 50)\n",
      "ADT PyG data: Data(x=[110673, 50], edge_index=[2, 1193139], y=[110673])\n",
      "✅ RNA and ADT data have same number of nodes\n",
      "✅ PyTorch Geometric conversion complete!\n"
     ]
    }
   ],
   "source": [
    "# Convert AnnData to PyTorch Geometric format\n",
    "print(\"=== Converting to PyTorch Geometric Format ===\")\n",
    "from scripts.data_provider.graph_data_builder import build_pyg_data\n",
    "# Convert RNA data\n",
    "print(\"Converting RNA data...\")\n",
    "rna_pyg_data = build_pyg_data(rna_adata_remaining)\n",
    "print(f\"RNA PyG data: {rna_pyg_data}\")\n",
    "\n",
    "# Convert ADT data\n",
    "print(\"Converting ADT data...\")\n",
    "adt_pyg_data = build_pyg_data(adt_adata_remaining)\n",
    "print(f\"ADT PyG data: {adt_pyg_data}\")\n",
    "\n",
    "\n",
    "if rna_pyg_data.num_nodes != adt_pyg_data.num_nodes:\n",
    "    print(\"⚠️  Warning: RNA and ADT data have different number of nodes!\")\n",
    "else:\n",
    "    print(\"✅ RNA and ADT data have same number of nodes\")\n",
    "\n",
    "print(\"✅ PyTorch Geometric conversion complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3963b525-8c6a-4d48-8c08-31120a7218aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AML samples: 83194\n",
      "Normal samples: 27479\n"
     ]
    }
   ],
   "source": [
    "# One-liner using pandas string methods\n",
    "rna_adata_remaining.obs['aml_labels'] = rna_adata_remaining.obs['samples'].str.startswith('AML').astype(int)\n",
    "\n",
    "# Convert to numpy array for training\n",
    "aml_labels_array = rna_adata_remaining.obs['aml_labels'].values\n",
    "\n",
    "# Check distribution\n",
    "print(f\"AML samples: {aml_labels_array.sum()}\")\n",
    "print(f\"Normal samples: {len(aml_labels_array) - aml_labels_array.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dcd8d13-2f3c-471e-8b85-12b08dead135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Extract labels from AnnData\n",
    "labels_series = rna_adata_remaining.obs['Cell_type_identity'].astype('category')\n",
    "\n",
    "# 2) Map to integer classes\n",
    "celltype_to_idx = {cat: i for i, cat in enumerate(labels_series.cat.categories)}\n",
    "idx_to_celltype = {i: cat for cat, i in celltype_to_idx.items()}\n",
    "celltype_labels = labels_series.cat.codes.to_numpy()  # shape [N], ints in [0, C-1]\n",
    "num_cell_types = len(celltype_to_idx)\n",
    "num_cell_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "761d3d26-6a24-4285-bb48-f5900e36c007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model from DeepOMAPNet_weights.pth...\n",
      "✅ Model loaded successfully!\n",
      "============================================================\n",
      "FINE-TUNING DEEPOMAPNET MODEL\n",
      "============================================================\n",
      "Device: cuda\n",
      "Epochs: 600\n",
      "Learning rate: 0.0001\n",
      "Freeze encoder: False\n",
      "Data shapes:\n",
      "  RNA: torch.Size([110673, 2000])\n",
      "  ADT targets: torch.Size([110673, 279])\n",
      "\n",
      "Trainable parameters: 483,503 / 483,503 (100.0%)\n",
      "\n",
      "Starting fine-tuning...\n",
      "Epoch 1/600 | ADT Loss: 0.779449 | AML Loss: 0.884034 | CellType Loss: 2.200339 | Total Loss: 3.863822\n",
      "Epoch 60/600 | ADT Loss: 0.758864 | AML Loss: 0.432907 | CellType Loss: 2.177469 | Total Loss: 3.369240\n",
      "Epoch 120/600 | ADT Loss: 0.754847 | AML Loss: 0.317327 | CellType Loss: 2.157536 | Total Loss: 3.229710\n",
      "Epoch 180/600 | ADT Loss: 0.749220 | AML Loss: 0.300951 | CellType Loss: 2.141824 | Total Loss: 3.191995\n",
      "Epoch 240/600 | ADT Loss: 0.748075 | AML Loss: 0.295211 | CellType Loss: 2.127924 | Total Loss: 3.171210\n",
      "Epoch 300/600 | ADT Loss: 0.743310 | AML Loss: 0.290573 | CellType Loss: 2.108609 | Total Loss: 3.142492\n",
      "Epoch 360/600 | ADT Loss: 0.741535 | AML Loss: 0.286433 | CellType Loss: 2.095719 | Total Loss: 3.123688\n",
      "Epoch 420/600 | ADT Loss: 0.737866 | AML Loss: 0.284975 | CellType Loss: 2.085476 | Total Loss: 3.108317\n",
      "Epoch 480/600 | ADT Loss: 0.736000 | AML Loss: 0.282863 | CellType Loss: 2.078089 | Total Loss: 3.096952\n",
      "Epoch 540/600 | ADT Loss: 0.734683 | AML Loss: 0.280062 | CellType Loss: 2.064523 | Total Loss: 3.079268\n",
      "Epoch 600/600 | ADT Loss: 0.732944 | AML Loss: 0.277884 | CellType Loss: 2.051183 | Total Loss: 3.062011\n",
      "\n",
      "✅ Fine-tuning complete!\n",
      "\n",
      "Final metrics after fine-tuning:\n",
      "  MSE: 0.677683\n",
      "  R²: 0.3420\n",
      "  CellType Acc: 0.5392  F1-macro: 0.1633\n"
     ]
    }
   ],
   "source": [
    "from scripts.trainer.fineTune import fine_tune_model, load_and_finetune\n",
    "\n",
    "fine_tuned_model = load_and_finetune(\n",
    "    model_path=\"DeepOMAPNet_weights.pth\",\n",
    "    rna_data=rna_adata_remaining,\n",
    "    adt_data=adt_adata_remaining,\n",
    "    aml_labels=aml_labels_array,\n",
    "    model_params={\n",
    "        'in_channels': 2000,\n",
    "        'hidden_channels': 32,\n",
    "        'out_channels': 279,\n",
    "        'heads': 2,\n",
    "        'dropout': 0.6,\n",
    "        'nhead': 2,\n",
    "        'num_layers': 1,\n",
    "        'use_adapters': True,\n",
    "        'reduction_factor': 4,\n",
    "        'adapter_l2_reg': 5e-5,\n",
    "        'use_positional_encoding': True,\n",
    "        'num_cell_types': 54\n",
    "    },\n",
    "    # pass these as function args, not model_params\n",
    "    celltype_labels=celltype_labels,     # ndarray or tensor of class indices [N]\n",
    "    num_cell_types=54,                   # optional; enables head post-load if missing\n",
    "    celltype_weight=1.0,\n",
    "    epochs=600,\n",
    "    learning_rate=1e-4,\n",
    "    freeze_encoder=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e300adbe-a6f8-4fc8-bba6-bd7eb8c3e6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = fine_tuned_model\n",
    "\n",
    "# Option 2: Save only the weights\n",
    "torch.save(model.state_dict(), \"DeepOMAPNet_finetuned.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085f59b2-4177-4fdc-9e8d-d2303ac26067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scVI",
   "language": "python",
   "name": "scvi-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
